---
title: Insert title here
key: b00250667d0d70cb52717105aaa88908

---
## Feature Engineering

```yaml
type: "TitleSlide"
key: "c61f393389"
```

`@lower_third`

name: Eon Retief
title: Specialist Data Scientist, Absa Group Ltd


`@script`
In this video we'll learn about feature engineering, and how we can use this technique to extract additional features of potential value when building machine learning models.


---
## Preparation Material

```yaml
type: "FullSlide"
key: "af9044eee4"
center_content: false
```

`@part1`
![prerequisites.png](https://assets.datacamp.com/production/repositories/4477/datasets/9aee707ac80b5821a2d4292632df5a486014f638/prerequisites.png){{1}}


`@script`
The Pandas Foundations, Manipulating DataFrames with Pandas, and Feature Engineering with PySpark courses available on DataCamp are offer a good foundation.

These courses collectively cover the importance of feature engineering, as well as some basic techniques for manipulating dataframes that will be used in this course.


---
## Process of Feature Engineering

```yaml
type: "FullSlide"
key: "2074a67b34"
center_content: false
disable_transition: false
```

`@part1`
1. Imagine{{1}}
2. Create{{2}}
3. Implement{{3}}
4. Evaluate{{4}}
5. Improve{{5}}


`@script`
It is worth noting the typical process followed for feature engineering. There are five key steps involved:

1. Imagine      - brainstorming or theorizing features within the context of the 
                  business problem;
2. Create       - actually generating or extracting the features from existing data;
3. Implement    - consuming the engineered features in an actual model;
4. Evaluate     - assessing the impact of the features on the model performance;
5. And, improve - adjusting the features to improve the overall performance.

That said, let's start building some features.


---
## Time-based Features

```yaml
type: "FullCodeSlide"
key: "bef8eb8fbe"
```

`@part1`
```{python}
# Update the format of the 'date_time' to the appropriate date-time format
p_df['date_time'] = pd.to_datetime(p_df['date_time'], format = '%Y-%m-%d')
```{{1}}

```{python}
# Inspect the data types
p_df.dtypes
```{{2}}

```
...                     ...
date_time    datetime64[ns]
...                     ...
dtype: object
```{{3}}

```{python}
# Extract the day of the week from the 'date_time' column
p_df['dt_dow'] = p_df['date_time'].dt.dayofweek
```{{4}}


`@script`
The first type of feature considers time-based values. It is important to always ensure the correct format or data type is applied when using time-based features.

Here we can use the `to_datetime` function to ensure the correct formatting.

Once done, we can use the `dt` accessor object to extract the desired date-time properties, such as day of the week.


---
## Text-based Features

```yaml
type: "TwoRows"
key: "68d9abc58a"
```

`@part1`
| user_agent |
|---|
| Mozilla/5.0 (iPhone; CPU iPhone OS 12_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/16A366  |
|  Mozilla/5.0 (Linux; Android 8.0.0; ANE-LX1 Build/HUAWEIANE-LX1; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/71.0.3578.99 Mobile Safari/537.36 |{{1}}


`@part2`
| user_agent*                           |      | device    | os        | os_version |
|---------------------------------------|------|-----------|-----------|------------|
| ... iPhone; CPU iPhone OS 12_0 ...    |&rarr;| iPhone    | ios       | 12.0       |
| ... Linux; Android 8.0.0; ANE-LX1 ... |&rarr;| ANE-LX1   | and       | 8.0.0      |{{2}}


`@script`
Text-based features can yield many valuable insights through proper extraction. In this case we can use the `user_agent` feature to extract information about the enduser's device, such as the device type and operating system.


---
## Feature Extraction using Regular Expressions

```yaml
type: "FullCodeSlide"
key: "3fe0a51977"
center_content: false
```

`@part1`
```{python}
# Load the required libraries
import re

# Define a function to extract the operating system version
def os_version(s):
    # Determine the appropriate regular expression based on the device type
    regex = '(?<=Android ).*?(?=;)' if 'ANDROID' in s.upper() \
                else '(?<=iPhone OS ).*?(?=\s)'

    # Compile the regular expression into a pattern object
    pat = re.compile(regex)
    # Apply the search method to the compiled pattern object on the passed 
    # string and extract the first group matched by the regular expression
    res = pat.search(s).group(0)
    
    # Return the operating system version
    return res.replace('_', '.')    
```{{1}}


`@script`
We can use regular expressions to extract and return the desired components from text.

Here, we've create a small function to extract the operating system version from a given text value. The appropriate regular expression can be applied to find the operating system version located after the operating system type in the given text.


---
## Feature Extraction using Regular Expressions

```yaml
type: "FullCodeSlide"
key: "1b3a2c95ca"
```

`@part1`
```{python}
# Apply the custom function to extract the operating system version from the
# 'user_agent' column
p_df['os_version'] = p_df.apply(lambda r: os_version(r['user_agent']), \
                         axis = 1)
```{{1}}

```{python}
# Print a sample of records to inspect the result
print(p_df.head(5))
```{{2}}

```
                                          user_agent os_version
0  Mozilla/5.0 (iPhone; CPU iPhone OS 12_0 like M...       12.0
1  Mozilla/5.0 (Linux; Android 8.0.0; ANE-LX1 Bui...      8.0.0
2  Mozilla/5.0 (iPad; CPU OS 9_3_5 like Mac OS X)...      9.3.5
3  Mozilla/5.0 (Linux; Android 8.0.0; SM-G930V Bu...      8.0.0
4  Mozilla/5.0 (iPhone; CPU iPhone OS 11_4_1 like...     11.4.1
```{{3}}


`@script`
Next, we can apply the custom function to each row of our dataframe to extract the operating system version for each record and generate a new feature with the values.

We can inspect the result to see that our function works as we expect.


---
## Group and Aggregate

```yaml
type: "FullCodeSlide"
key: "f35d1c63ee"
```

`@part1`
```{python}
# Load the required libraries
from scipy.stats import mode

# Group the records at a user-level and calculate aggregate statistics
a_df = p_df \
    .groupby(['user_id']) \
    .agg({
        'app_id': 'count',
        'dt_dow': lambda x: mode(x)[0][0]
    }) \
    .reset_index()
```{{1}}

```{python}
# Print a sample of records to inspect the result
print(a_df.head(5))
```{{2}}

```
        user_id  app_id  dt_dow
0  8ABEC04C8CB5       1       5
1  8F07D20CDE57       1       2
2  04A7123CB0C4       1       5
3  5C0B36635BA2       1       4
4  82DEE041AFE1       1       3
```{{3}}


`@script`
Lastly, it is important to remember that we are building a model to predict at a user level. For this reason we need to group our bidding data by `user_id`. 

We can then generate aggregated features based on the grouped values for each user. In this case, we calculate the typical day of the week that the user was seen on.

These aggregated features can in turn be used to calculate other user-level metrics or statistics.


---
## Let's practice!

```yaml
type: "FinalSlide"
key: "3ed571bb29"
```

`@script`
Great! Now let's move on to the exercises to start practicing your skills.

